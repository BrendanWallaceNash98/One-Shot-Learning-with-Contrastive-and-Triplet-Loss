{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a08d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib as plt\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b747d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds, ds_info = tfds.load('omniglot', split=['train','test'],with_info=True, as_supervised = False)\n",
    "#ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3b7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pickle.load(open(\"TestDF_ds.pickle\", \"rb\"))\n",
    "train = pickle.load(open(\"TrainDF_ds.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec2929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fffd815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(ds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f567556",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.DataFrame(train)\n",
    "testDF = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "172c60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = trainDF[:8000]\n",
    "testDF = testDF[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef3bbff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_positive_pairs(df):\n",
    "    \n",
    "    list_image = []    \n",
    "    pairList= []\n",
    "    \n",
    "    uniqueAlph = df['alphabet'].unique()\n",
    "    \n",
    "    for i in range(len(uniqueAlph)):\n",
    "        alphDF = df[df['alphabet'] == i]\n",
    "        charUnique = alphDF['alphabet_char_id'].unique()\n",
    "        for i in range(len(charUnique)):\n",
    "            dfImage = alphDF[alphDF['alphabet_char_id'] == charUnique[i]]\n",
    "            \n",
    "            imagedf = dfImage['image'].copy()\n",
    "            imageList = imagedf.values.tolist()\n",
    "            \n",
    "            \n",
    "            list_image.append(imageList[0])\n",
    "            \n",
    "        x = 0 \n",
    "        pair_list = []\n",
    "        pair_target = []\n",
    "        list_image2 = list_image.copy()\n",
    "        for i in range(len(list_image)):\n",
    "            for x in range(len(list_image)):\n",
    "                pair_list.append([list_image[i], list_image2[x]])\n",
    "                pair_target.append(1.0)\n",
    "                \n",
    "                \n",
    "        random.shuffle(pair_list)       \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "    return pair_list, pair_target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c0d4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(data):\n",
    "        \n",
    "    \n",
    "    df = data.sort_values(by=['alphabet'])\n",
    "    \n",
    "    df_pairs_1 = df[df.index % 2 != 0]\n",
    "    \n",
    "    df_pairs_2 = df[df.index % 2 != 1]\n",
    "    \n",
    "    df_pairs_1 = shuffle(df_pairs_1)\n",
    "    \n",
    "    imagedf = df_pairs_1['image'].copy()\n",
    "    imageList = imagedf.values.tolist()\n",
    "    \n",
    "    alphabetdf = df_pairs_1['alphabet'].copy()\n",
    "    alphabetList = alphabetdf.values.tolist()\n",
    "    \n",
    "    imagedf2 = df_pairs_2['image'].copy()\n",
    "    imageList2 = imagedf.values.tolist()\n",
    "    \n",
    "    alphabetdf2 = df_pairs_2['alphabet'].copy()\n",
    "    alphabetList2 = alphabetdf.values.tolist()\n",
    "    \n",
    "    imageList2 = shuffle(imageList2)\n",
    "    imageList = shuffle(imageList)\n",
    "    alphabetList = shuffle(alphabetList)\n",
    "    alphabetList2 = shuffle(alphabetList2)\n",
    "    \n",
    "    trainList = []\n",
    "    testList = []\n",
    "    \n",
    "    for i in range(len(alphabetList)):\n",
    "        loopList = []\n",
    "        pos = 1.0\n",
    "        neg = 0.0\n",
    "        if alphabetList[i] == alphabetList2[i]:\n",
    "            loopList.append(imageList[i].astype(float))\n",
    "            loopList.append(imageList2[i].astype(float))\n",
    "            testList.append(pos)\n",
    "            trainList.append(loopList)\n",
    "        else:\n",
    "            loopList.append(imageList[i].astype(float))\n",
    "            loopList.append(imageList2[i].astype(float))\n",
    "            testList.append(neg)\n",
    "            trainList.append(loopList)\n",
    "    \n",
    "    return trainList, testList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ebc036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_neg_pairs(list_bin):\n",
    "    x = 1\n",
    "    count = []\n",
    "    for i in range(len(list_bin)):\n",
    "        if list_bin[i] == 0.0:\n",
    "            count.append(x)\n",
    "        else:\n",
    "            pass\n",
    "    print(len(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3276b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pairs(train1, test1, train2, test2):\n",
    "    for i in range(len(train2)):\n",
    "        train1.append(train2[i])\n",
    "    \n",
    "    \n",
    "    for i in range(len(test2)):\n",
    "        test1.append(test2[i])\n",
    "    \n",
    "    shuffleList = list(zip(train1, test1))\n",
    "                       \n",
    "    random.shuffle(shuffleList)\n",
    "    \n",
    "    train1, test1 = zip(*shuffleList)\n",
    "                       \n",
    "    train1 = np.array(train1)\n",
    "    test1 = np.array(test1)\n",
    "    \n",
    "    train1/225\n",
    "\n",
    "    \n",
    "    return train1, test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b6ccc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = get_pairs(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3be1ab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3874\n"
     ]
    }
   ],
   "source": [
    "count_neg_pairs(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14a3ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainXPos, trainYPos = make_positive_pairs(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e10e2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainXPos = trainXPos[0:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a9fb2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainYPos = trainYPos[0:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba8e88ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainXFinal, trainYFinal= combine_pairs(trainXPos, trainYPos, trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94d3caca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainYFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fce4b045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainXFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cf68d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainYFinal = trainYFinal.reshape(69640, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "021a54cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3874\n"
     ]
    }
   ],
   "source": [
    "count_neg_pairs(trainYFinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14261242",
   "metadata": {},
   "source": [
    "test data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1cba084",
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testY = get_pairs(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fc19612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952\n"
     ]
    }
   ],
   "source": [
    "count_neg_pairs(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "238613a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testXPos, testYPos = make_positive_pairs(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b79b635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count_neg_pairs(testYPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92d05144",
   "metadata": {},
   "outputs": [],
   "source": [
    "testXFinal, testYFinal= combine_pairs(testXPos, testYPos, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7d06b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "testXPos = testXPos[:5000]\n",
    "testYPos = testYPos[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20ec1034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pickle\\npickle_out = open(\"trainXFinal.pickle\", \"wb\")\\npickle.dump(trainXFinal, pickle_out)\\npickle_out.close()\\n\\npickle_out = open(\"trainYPos.pickle\", \"wb\")\\npickle.dump(trainYPos, pickle_out)\\npickle_out.close()\\n\\npickle_out = open(\"testXFinal.pickle\", \"wb\")\\npickle.dump(testXFinal, pickle_out)\\npickle_out.close()\\n\\npickle_out = open(\"testYFinal.pickle\", \"wb\")\\npickle.dump(testYFinal, pickle_out)\\npickle_out.close()\\n\\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pickle\n",
    "pickle_out = open(\"trainXFinal.pickle\", \"wb\")\n",
    "pickle.dump(trainXFinal, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"trainYPos.pickle\", \"wb\")\n",
    "pickle.dump(trainYPos, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"testXFinal.pickle\", \"wb\")\n",
    "pickle.dump(testXFinal, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"testYFinal.pickle\", \"wb\")\n",
    "pickle.dump(testYFinal, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4461acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "#import wandb\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input, Lambda, Dot\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c367eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(trainXFinal, trainYFinal, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0b7a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenX = round(len(trainXFinal)*0.20)\n",
    "lenY = round(len(trainYFinal)*0.20)\n",
    "X_train = trainXFinal[lenX:]\n",
    "X_test = trainYFinal[lenX:]\n",
    "y_train = trainXFinal[:lenY]\n",
    "y_test = trainYFinal[:lenY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1ffc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 16\n",
    "margin = 1  # Margin for constrastive loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99943ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided two tensors t1 and t2\n",
    "# Euclidean distance = sqrt(sum(square(t1-t2)))\n",
    "def euclidean_distance(vects):\n",
    "    \"\"\"Find the Euclidean distance between two vectors.\n",
    "\n",
    "    Arguments:\n",
    "        vects: List containing two tensors of same length.\n",
    "\n",
    "    Returns:\n",
    "        Tensor containing euclidean distance\n",
    "        (as floating point value) between vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "\n",
    "input = layers.Input((105, 105, 3))\n",
    "x = tf.keras.layers.BatchNormalization()(input)\n",
    "x = layers.Conv2D(16, (3, 3), activation=\"relu\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = layers.Dense(64, activation=\"tanh\")(x)\n",
    "embedding_network = keras.Model(input, x)\n",
    "\n",
    "\n",
    "input_1 = layers.Input((105, 105, 3))\n",
    "input_2 = layers.Input((105, 105, 3))\n",
    "\n",
    "# As mentioned above, Siamese Network share weights between\n",
    "# tower networks (sister networks). To allow this, we will use\n",
    "# same embedding network for both tower networks.\n",
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = layers.Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "normal_layer = tf.keras.layers.BatchNormalization()(merge_layer)\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(normal_layer)\n",
    "siamese = keras.Model(inputs=[input_1, input_2], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cabb87f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(margin=1):\n",
    "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
    "\n",
    "  Arguments:\n",
    "      margin: Integer, defines the baseline for distance for which pairs\n",
    "              should be classified as dissimilar. - (default is 1).\n",
    "\n",
    "  Returns:\n",
    "      'constrastive_loss' function with data ('margin') attached.\n",
    "  \"\"\"\n",
    "\n",
    "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
    "    #                         true_value * square( max(margin-prediction, 0) ))\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        \"\"\"Calculates the constrastive loss.\n",
    "\n",
    "      Arguments:\n",
    "          y_true: List of labels, each label is of type float32.\n",
    "          y_pred: List of predictions of same length as of y_true,\n",
    "                  each label is of type float32.\n",
    "\n",
    "      Returns:\n",
    "          A tensor containing constrastive loss as floating point value.\n",
    "      \"\"\"\n",
    "\n",
    "        square_pred = tf.math.square(y_pred)\n",
    "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        return tf.math.reduce_mean(\n",
    "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        )\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9eb17b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 105, 105, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 105, 105, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 64)           1258540     input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           model[0][0]                      \n",
      "                                                                 model[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1)            4           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 1,258,546\n",
      "Trainable params: 1,221,674\n",
      "Non-trainable params: 36,872\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese.compile(loss=loss(margin=margin), optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2225aefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 132s 108ms/step - loss: 0.1763 - accuracy: 0.7559 - val_loss: 0.2259 - val_accuracy: 0.6310\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 128s 107ms/step - loss: 0.1087 - accuracy: 0.8503 - val_loss: 0.1349 - val_accuracy: 0.8400\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 122s 101ms/step - loss: 0.0861 - accuracy: 0.8808 - val_loss: 0.1551 - val_accuracy: 0.8396\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 121s 101ms/step - loss: 0.0749 - accuracy: 0.8979 - val_loss: 0.0780 - val_accuracy: 0.8994\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 123s 102ms/step - loss: 0.0745 - accuracy: 0.8961 - val_loss: 0.0552 - val_accuracy: 0.9329\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 122s 102ms/step - loss: 0.0647 - accuracy: 0.9140 - val_loss: 0.1474 - val_accuracy: 0.8417\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 122s 101ms/step - loss: 0.0766 - accuracy: 0.8965 - val_loss: 0.0972 - val_accuracy: 0.8675\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 122s 102ms/step - loss: 0.0644 - accuracy: 0.9151 - val_loss: 0.1603 - val_accuracy: 0.8394\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 122s 102ms/step - loss: 0.0639 - accuracy: 0.9174 - val_loss: 0.0809 - val_accuracy: 0.8885\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 122s 102ms/step - loss: 0.0570 - accuracy: 0.9271 - val_loss: 0.0825 - val_accuracy: 0.8810\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 123s 102ms/step - loss: 0.0525 - accuracy: 0.9352 - val_loss: 0.1270 - val_accuracy: 0.8521\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 122s 102ms/step - loss: 0.0540 - accuracy: 0.9312 - val_loss: 0.0754 - val_accuracy: 0.8946\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 122s 102ms/step - loss: 0.0596 - accuracy: 0.9256 - val_loss: 0.1035 - val_accuracy: 0.8742\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 122s 102ms/step - loss: 0.0514 - accuracy: 0.9400 - val_loss: 0.0949 - val_accuracy: 0.8779\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 122s 102ms/step - loss: 0.0518 - accuracy: 0.9382 - val_loss: 0.0761 - val_accuracy: 0.9048\n",
      "Epoch 16/20\n",
      "1200/1200 [==============================] - 121s 101ms/step - loss: 0.0508 - accuracy: 0.9395 - val_loss: 0.0860 - val_accuracy: 0.8977\n",
      "Epoch 17/20\n",
      "1200/1200 [==============================] - 122s 102ms/step - loss: 0.0507 - accuracy: 0.9403 - val_loss: 0.0582 - val_accuracy: 0.9242\n",
      "Epoch 18/20\n",
      "1200/1200 [==============================] - 122s 101ms/step - loss: 0.0488 - accuracy: 0.9438 - val_loss: 0.0605 - val_accuracy: 0.9262\n",
      "Epoch 19/20\n",
      "1200/1200 [==============================] - 121s 101ms/step - loss: 0.0486 - accuracy: 0.9436 - val_loss: 0.0832 - val_accuracy: 0.8992\n",
      "Epoch 20/20\n",
      "1200/1200 [==============================] - 122s 102ms/step - loss: 0.0542 - accuracy: 0.9344 - val_loss: 0.0711 - val_accuracy: 0.9127\n"
     ]
    }
   ],
   "source": [
    "history = siamese.fit(\n",
    "    [X_train[:,0], X_train[:,1]],\n",
    "    X_test[:],\n",
    "    validation_data=([y_train[:,0], y_train[:,1]], y_test[:]),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f6d16b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0][0] = y_train[0][0].reshape(-1, 105, 105, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a504974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0][1] = y_train[0][1].reshape(-1, 105, 105, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = siamese.predict([y_train[:, 0].reshape(-1, 105, 105, 3), y_train[:, 1].reshape(-1, 105, 105, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8e5d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(X_value, y_value):\n",
    "    predictions = []\n",
    "    count = 0\n",
    "    for i in range(len(X_value)):\n",
    "        prediction = siamese.predict([X_value[i][0].reshape(-1, 105, 105, 3), X_value[i][1].reshape(-1, 105, 105, 3)])\n",
    "        if prediction > 0.5:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    for i in range(len(testXFinal)):\n",
    "        if predictions[i] == y_value[i]:\n",
    "            counts = counts+1\n",
    "    accurracy = (counts/len(testXFinal))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef5ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = get_result(testXFinal, testYFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6d880",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = get_result(trainXFinal, trainYFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1f21203",
   "metadata": {},
   "outputs": [],
   "source": [
    "testXFinal = np.array(testXFinal)\n",
    "trainYFinal = np.array(trainYFinal)\n",
    "testYFinal = np.array(testYFinal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f94f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testXFinal = np.array(testXFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixX = np.concatenate(trainXFinal[:100],trainXFinal[:100])\n",
    "mixY = np.concatenate(testYFinal[:100],trainYFinal[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_acc = get_result(mixX, mixY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f50a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Print(\"train accuracy is {}%\".format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28577352",
   "metadata": {},
   "outputs": [],
   "source": [
    "Print(\"test accuracy is {}%\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc3bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Print(\"mix of train and test accuracy is {}%\".format(mix_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
